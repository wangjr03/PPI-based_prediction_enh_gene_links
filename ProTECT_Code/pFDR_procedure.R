#generate distribution of if vs distance
#argument list:
# 1. path to the significant Hi-C interactions, i.e. GSE63525_K562_HiCCUPS_looplist.txt.gz
# 2. path to the all potential enhancer-promoter interactions after filtering with PPI score
# 3. path to the predictive probability based on the pre-trained random forest model
# 4. path to the background predictive probability based on the pre-trained random forest model, can be generated by applying the model on shuffled feature matrix, check the paper for details.
# 5. output path of the scores, i.e. p-values and q-values, for all pairs
# 6. output path of the predicted significant interactions.

arsg <- commandArgs(T)


gs <- data.table::fread(args[1])
dist = abs((gs$x1+gs$x2)/2-(gs$y1+gs$y2)/2)
dist= dist[which(dist < 1e6)]
d_bin <- floor(dist[which(dist<1e6)]/1e4)

weight <- hist(dist, 200, plot = FALSE)
weight <- list()
f <- function(s){s^(-3/2)*exp(-1400/s^2)}
mids <- c()
breaks <- seq(0,1e6,1e4)
breaks[1] <- 1e-10
f_weight <- c()
for(i in 1:100){

  f_weight[i] <- sum(f(breaks[i]:breaks[i+1]))
  mids[i] <- (breaks[i]+breaks[i+1])/2

}

weight$density <- f_weight
weight$breaks <- breaks
weight$mids <- mids


pi.0 <- 1-0.01*weight$density/weight$density[2]
pi.0[1] <- 0.99

pFDR <- function(my_pi.0,lambda,p){
  
  tp <- my_pi.0*lambda/(mean(!(p>lambda)))
  
  return(tp)
}


#for each bin, calculate q val

q_val <- function(my_p_vec,my_pi.0){
  
  #sort p_val_vec
  p_val.order <- order(my_p_vec)
  p_val.sort <- my_p_vec[p_val.order]
  
  #calculate pFDR
  m <- length(my_p_vec)
  
  temp_q <- rep(0,m)
  
  temp_q[m] <- pFDR(my_pi.0,p_val.sort[m],p_val.sort)
  
  #calculate q
  for(i in (m-1):1){
    
    temp_q[i] <- min(temp_q[(i+1):m],pFDR(my_pi.0,p_val.sort[i],p_val.sort))
    
  }
  
  #reorder q value
  
  my_q_val <- c()
  
  my_q_val[p_val.order] <- temp_q
  
  return(my_q_val)
  
}


calculate_p <- function(bg_dist,x,N){
  
  n <- 1+x/1e-4
  
  tmp_p = sum(bg_dist$counts[n:1e4])/N
  
  return(tmp_p)
}

calculate_p <- Vectorize(calculate_p,vectorize.args = 'x')

#get prediction
all_pair <- read.table(args[2],colClasses = c('character',rep('numeric',4),rep('NULL',15000)),fill=T)
colnames(all_pair) <- c('Chr','Enhancer_start','Enhancer_end','Promoter_start','Promoter_end')
all_pair$Distance = abs((all_pair$Enhancer_start + all_pair$Enhancer_end)/2 - (all_pair$Promoter_start + all_pair$Promoter_end)/2 )
all_prob <- read.table(args[3])[,1]
bg_prob <- read.table(args[4])[,1]
#calculate p value
bg_dist = hist(bg_prob,1e4,plot=FALSE,breaks=seq(0,1,by=1e-4))
N <- length(bg_prob)
all_p_val <- calculate_p(bg_dist,all_prob,N)
  
all_data  <- data.frame(Distance=all_pair$Distance,pval = all_p_val)

all_pair <- cbind(all_pair,all_data)
all_pair$prob = all_prob
#info.frame$distance[which(info.frame$distance>2e6)] <- 2e6

weight$breaks[1] <- -1
re <- list()
full_q <- list()
for(i in 1:100){
  
  start <- weight$breaks[i]
  
  stop <- weight$breaks[i+1]
  
  #subsetdata
  temp_data <- subset(all_pair,(all_pair$Distance>start)&(!all_pair$Distance>stop))
  
  temp_p <- temp_data$pval
  
  temp_q <- q_val(temp_p,pi.0[i])
  
  #sig_pair[[i]] <- cbind(temp_data[which(temp_q<0.01),],temp_q[which(temp_q<0.01)])
  print(length(which(temp_q<0.01)))
  temp_data <- cbind(temp_data,temp_q)
  full_q[[i]] <- temp_data
  re[[i]] <- temp_data
  print(i)
}

all_score <- do.call(rbind,full_q)
colnames(all_score)[10] <- 'q_val'
all_score <- all_score[,-7]
#all_score$Prob = all_prob
prediction = subset(all_score,all_score$q_val < 0.01)
write.table(all_score,args[5],col.names = F,row.names = F,sep="\t",quote=F)
write.table(prediction,args[6],col.names = F,row.names = F,sep="\t",quote=F)
